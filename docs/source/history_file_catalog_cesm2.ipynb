{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "willing-advertising",
   "metadata": {},
   "source": [
    "# Building an Intake-esm catalog from CESM2 History Files\n",
    "\n",
    "This example covers how to build an intake-esm catalog from Community Earth System Model v2 (CESM2) model output. In this case, we use model output using the default component-set (compset) detailed in the [CESM Quickstart Guide](https://escomp.github.io/CESM/versions/cesm2.1/html/).\n",
    "\n",
    "## What's a \"history\" file?\n",
    "A history file is the default output from CESM, where each file is a single time \"slice\" with every variable from the component of interest. These types of files can be difficult to work with, since often times one is interested in a time series of a single variable. Building a catalog can be helpful in accessing your data, querying for certain variables, and potentially creating timeseries files later down the road.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Imports\n",
    "The only parts of ecgtools we need are the `Builder` object and the `parse_cesm_history` parser from the CESM parsers! We import `glob` to take a look at the files we are parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecgtools import Builder\n",
    "from ecgtools.parsers.cesm import parse_cesm_history\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-rings",
   "metadata": {},
   "source": [
    "### Understanding the Directory Structure\n",
    "\n",
    "The first step to setting up the `Builder` object is determining where your files are stored. As mentioned previously, we have a sample dataset of CESM2 model output, which is stored in `/glade/work/mgrover/cesm_test_data/`\n",
    "\n",
    "Taking a look at that directory, we see that there is a single case `b.e20.B1850.f19_g17.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/glade/work/mgrover/cesm_test_data/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-stock",
   "metadata": {},
   "source": [
    "Once we go into that directory, we see all the different components, including the atmosphere (atm), ocean (ocn), and land (lnd)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/glade/work/mgrover/cesm_test_data/b.e20.B1850.f19_g17.test/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-graham",
   "metadata": {},
   "source": [
    "If we go one step further, we notice that within each component, is a `hist` directory which contains the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/glade/work/mgrover/cesm_test_data/b.e20.B1850.f19_g17.test/atm/*/*.nc')[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-cabin",
   "metadata": {},
   "source": [
    "If we take a look at the `ocn` component though, we notice that there are a few timeseries files in there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/glade/work/mgrover/cesm_test_data/b.e20.B1850.f19_g17.test/ocn/*/*.nc')[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-sauce",
   "metadata": {},
   "source": [
    "When we setup our catalog builder, we will need to specify not including the timeseries (tseries) and restart (rest) directories!\n",
    "\n",
    "Now that we understand the directory structure, let's make the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-nursery",
   "metadata": {},
   "source": [
    "## Build the catalog!\n",
    "\n",
    "Let's start by inspecting the builder object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Builder(\n",
    "    # Directory with the output\n",
    "    \"/glade/work/mgrover/cesm_test_data/b.e20.B1850.f19_g17.test/\",\n",
    "    \n",
    "    # Depth of 1 since we are sending it to the case output directory\n",
    "    depth=1,\n",
    "    \n",
    "    # Use the parse_cesm_history parsing function\n",
    "    parsing_func=parse_cesm_history,\n",
    "    \n",
    "    # Exclude the timeseries and restart directories\n",
    "    exclude_patterns=[\"*/tseries/*\", \"*/rest/*\"],\n",
    "    \n",
    "    # Number of jobs to execute - should be equal to # threads you are using\n",
    "    njobs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-correlation",
   "metadata": {},
   "source": [
    "Double check the object is set up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-chile",
   "metadata": {},
   "source": [
    "We are good to go! Let's build the catalog by calling `.build()` on the object! By default, it will use the `LokyBackend` which is described in the [Joblib documentation](https://joblib.readthedocs.io/en/latest/parallel.html). Essentially, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-apollo",
   "metadata": {},
   "source": [
    "## Inspect the Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-syndrome",
   "metadata": {},
   "source": [
    "Now that the catalog is built, we can inspect the dataframe which is used to create the catalog by calling `.df` on the builder object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-finish",
   "metadata": {},
   "source": [
    "The resultant dataframe includes the:\n",
    "* Component\n",
    "* Stream\n",
    "* Case\n",
    "* Date\n",
    "* Frequency\n",
    "* Variables\n",
    "* Path\n",
    "\n",
    "We can also check to see which files ***were not*** parsed by calling `.invalid_assets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.invalid_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.invalid_assets.INVALID_ASSET.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-august",
   "metadata": {},
   "source": [
    "It appears that one of the invalid assets is a `pop.hv` stream, which is a time-invariant dataset we would not neccessarily be interested in looking at. If there is a file you think ***should*** be included in the resultant catalog but isn't, be sure to add it to the `_STREAMS_DICT` used in the [parsing tool](https://github.com/NCAR/ecgtools/blob/main/ecgtools/parsers/cesm.py)! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-egypt",
   "metadata": {},
   "source": [
    "## Save the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.save(\n",
    "    # File path - could save as .csv (uncompressed csv) or .csv.gz (compressed csv)\n",
    "    \"/glade/work/mgrover/cesm-hist-test.csv\",\n",
    "    \n",
    "    # Column name including filepath\n",
    "    path_column='path',\n",
    "    \n",
    "    # Column name including variables\n",
    "    variable_column='variables',\n",
    "    \n",
    "    # Data file format - could be netcdf or zarr (in this case, netcdf)\n",
    "    data_format=\"netcdf\",\n",
    "    \n",
    "    # Which attributes to groupby when reading in variables using intake-esm\n",
    "    groupby_attrs=[\"component\", \"stream\", \"case\"],\n",
    "    \n",
    "    # Aggregations which are fed into xarray when reading in data using intake\n",
    "    aggregations=[\n",
    "        {\n",
    "            \"type\": \"join_existing\",\n",
    "            \"attribute_name\": \"date\",\n",
    "            \"options\": {\"dim\": \"time\", \"coords\": \"minimal\", \"compat\": \"override\"},\n",
    "        }\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-architecture",
   "metadata": {},
   "source": [
    "## Using the Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-state",
   "metadata": {},
   "source": [
    "You'll notice the resultant filepaths are output when calling `.save` - which you could use within your intake-esm `open_esm_datastore` function.\n",
    "\n",
    "### Additional Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import intake-esm\n",
    "import intake\n",
    "\n",
    "# Import ast which helps with parsing the list of variables\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-controversy",
   "metadata": {},
   "source": [
    "### Use the catalog to read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\n",
    "    \"/glade/work/mgrover/cesm-hist-test.json\", \n",
    "    csv_kwargs={\"converters\": {\"variables\": ast.literal_eval}}, sep=\"/\"\n",
    ")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = col.search(variables='TEMP', \n",
    "                 case='b.e20.b1850.f19_g17.test')\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = cat.to_dataset_dict(cdf_kwargs={'use_cftime': True, 'chunks': {'time':10}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-hires-marbl]",
   "language": "python",
   "name": "conda-env-miniconda3-hires-marbl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
